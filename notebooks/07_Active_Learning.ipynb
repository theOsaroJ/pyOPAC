{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from copy import deepcopy\n",
    "\n",
    "# Import required modules\n",
    "from opac.data.dataset import MoleculeDataset\n",
    "from opac.models.trainer import train_model, evaluate_model\n",
    "from opac.active_learning.predict_with_uncertainty import predict_with_uncertainty\n",
    "from opac.active_learning.uncertainty_sampling import select_most_uncertain_samples\n",
    "from opac.utils.logger import get_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = get_logger(__name__)\n",
    "\n",
    "# Set hyperparameters for active learning\n",
    "initial_train_size = 1000\n",
    "query_size = 5\n",
    "requested_iterations = 2  # maximum number of active learning iterations\n",
    "hidden_dim = 128\n",
    "epochs = 50\n",
    "batch_size = 32\n",
    "learning_rate = 1e-3\n",
    "weight_decay = 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "descriptors_file = os.path.join(\"dataset\", \"descriptors.csv\")\n",
    "targets_file = os.path.join(\"dataset\", \"targets.csv\")\n",
    "model_output = os.path.join(\"saved_models\", \"al_trained_model.pth\")\n",
    "final_al_training_data = os.path.join(\"dataset\", \"final_al_training_data.csv\")\n",
    "\n",
    "# Load the descriptors and targets from CSV files\n",
    "df_descriptors = pd.read_csv(descriptors_file)\n",
    "df_targets = pd.read_csv(targets_file)\n",
    "\n",
    "# Merge the data on 'mol_id'\n",
    "df = pd.merge(df_descriptors, df_targets, on=\"mol_id\")\n",
    "descriptor_columns = [col for col in df_descriptors.columns if col != \"mol_id\"]\n",
    "target_columns = [col for col in df_targets.columns if col != \"mol_id\"]\n",
    "\n",
    "# Initialize the labeled (training) and unlabeled datasets\n",
    "initial_train_df = df.sample(n=initial_train_size, random_state=42)\n",
    "unlabeled_df = df.drop(initial_train_df.index).reset_index(drop=True)\n",
    "\n",
    "logger.info(f\"Initial training set size: {len(initial_train_df)}\")\n",
    "logger.info(f\"Unlabeled set size: {len(unlabeled_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the maximum possible iterations based on available unlabeled data\n",
    "max_possible_iterations = (len(df) - initial_train_size) // query_size\n",
    "iterations = min(requested_iterations, max_possible_iterations)\n",
    "if iterations == 0:\n",
    "    logger.info(\"Not enough data for the specified iterations and query size.\")\n",
    "else:\n",
    "    logger.info(f\"Active learning will run for {iterations} iterations.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iteration in range(iterations):\n",
    "    logger.info(f\"--- Active Learning Iteration {iteration + 1}/{iterations} ---\")\n",
    "\n",
    "    # Create training dataset from the current labeled data\n",
    "    train_descriptors = initial_train_df[descriptor_columns].to_dict(\"records\")\n",
    "    train_targets = initial_train_df[target_columns].to_dict(\"records\")\n",
    "    train_dataset = MoleculeDataset(train_descriptors, train_targets)\n",
    "\n",
    "    # Create test dataset using the remaining data\n",
    "    test_df = df.drop(initial_train_df.index).reset_index(drop=True)\n",
    "    test_descriptors = test_df[descriptor_columns].to_dict(\"records\")\n",
    "    test_targets = test_df[target_columns].to_dict(\"records\")\n",
    "    test_dataset = MoleculeDataset(test_descriptors, test_targets)\n",
    "\n",
    "    # Determine model dimensions\n",
    "    input_dim = len(descriptor_columns)\n",
    "    output_dim = len(target_columns)\n",
    "\n",
    "    # Train or continue training the model using the current labeled dataset\n",
    "    model = train_model(\n",
    "        dataset=train_dataset,\n",
    "        input_dim=input_dim,\n",
    "        output_dim=output_dim,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        learning_rate=learning_rate,\n",
    "        hidden_dim=hidden_dim,\n",
    "        weight_decay=weight_decay\n",
    "    )\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    test_loss, per_target_metrics = evaluate_model(model, test_dataset, batch_size=batch_size)\n",
    "    logger.info(f\"Iteration {iteration + 1} - Test Loss: {test_loss:.4f}\")\n",
    "    for m in per_target_metrics:\n",
    "        i = m[\"target_index\"]\n",
    "        logger.info(f\"[Target {i}] MSE={m['MSE']:.4f}, MAE={m['MAE']:.4f}, R2={m['R2_Score']:.4f}\")\n",
    "\n",
    "    # If there is no more unlabeled data, stop the loop\n",
    "    if unlabeled_df.empty:\n",
    "        logger.info(\"No more unlabeled samples. Stopping active learning.\")\n",
    "        break\n",
    "    \n",
    "    # Use Monte Carlo Dropout to predict on unlabeled data and estimate uncertainty\n",
    "    unlabeled_descriptors = unlabeled_df[descriptor_columns].to_dict(\"records\")\n",
    "    unlabeled_dataset = MoleculeDataset(unlabeled_descriptors, targets=None)\n",
    "    predictions, uncertainties = predict_with_uncertainty(model, unlabeled_dataset, batch_size=batch_size)\n",
    "\n",
    "    # Select the samples with the highest uncertainty\n",
    "    current_query_size = min(query_size, len(unlabeled_df))\n",
    "    query_indices = select_most_uncertain_samples(uncertainties, current_query_size)\n",
    "\n",
    "    # Add the queried samples to the labeled dataset\n",
    "    queried_samples = unlabeled_df.iloc[query_indices]\n",
    "    initial_train_df = pd.concat([initial_train_df, queried_samples], ignore_index=True)\n",
    "\n",
    "    # Remove the queried samples from the unlabeled dataset\n",
    "    unlabeled_df = unlabeled_df.drop(queried_samples.index).reset_index(drop=True)\n",
    "    logger.info(f\"Iteration {iteration + 1}: Queried {len(queried_samples)} samples.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final active learning model\n",
    "output_dir = os.path.dirname(model_output)\n",
    "if output_dir and not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "    logger.info(f\"Created directory {output_dir}.\")\n",
    "torch.save(model, model_output)\n",
    "logger.info(f\"Active Learning completed. Final model saved to {model_output}\")\n",
    "\n",
    "# Save the final active learning training dataset\n",
    "initial_train_df.to_csv(final_al_training_data, index=False)\n",
    "logger.info(f\"Final AL training data saved to {final_al_training_data}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
