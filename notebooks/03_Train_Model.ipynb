{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our unified dataset and training functions\n",
    "from opac.data.dataset import MoleculeDataset\n",
    "from opac.models.trainer import train_model, evaluate_model\n",
    "\n",
    "# Load descriptors and targets\n",
    "df_descriptors = pd.read_csv(os.path.join(\"dataset\", \"descriptors.csv\"))\n",
    "df_targets = pd.read_csv(os.path.join(\"dataset\", \"targets.csv\"))\n",
    "\n",
    "# Ensure 'mol_id' is numeric and merge on 'mol_id'\n",
    "df_descriptors['mol_id'] = df_descriptors['mol_id'].astype(int)\n",
    "df_targets['mol_id'] = df_targets['mol_id'].astype(int)\n",
    "df = pd.merge(df_descriptors, df_targets, on='mol_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify descriptor and target columns\n",
    "descriptor_cols = [col for col in df_descriptors.columns if col != 'mol_id']\n",
    "target_cols = [col for col in df_targets.columns if col != 'mol_id']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "train_descriptors = train_df[descriptor_cols].to_dict('records')\n",
    "train_targets = train_df[target_cols].to_dict('records')\n",
    "test_descriptors = test_df[descriptor_cols].to_dict('records')\n",
    "test_targets = test_df[target_cols].to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "train_dataset = MoleculeDataset(train_descriptors, train_targets)\n",
    "test_dataset  = MoleculeDataset(test_descriptors, test_targets)\n",
    "\n",
    "# Get dimensions for model input/output\n",
    "input_dim = train_dataset.input_dim\n",
    "output_dim = train_dataset.output_dim\n",
    "\n",
    "# Train the model\n",
    "model = train_model(\n",
    "    dataset=train_dataset,\n",
    "    input_dim=input_dim,\n",
    "    output_dim=output_dim,\n",
    "    epochs=200,\n",
    "    batch_size=64,\n",
    "    learning_rate=0.001,\n",
    "    hidden_dim=512,\n",
    "    weight_decay=1e-4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model and parameters\n",
    "model_path = os.path.join(\"saved_models\", \"trained_model.pth\")\n",
    "os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(f\"Model saved to {model_path}\")\n",
    "\n",
    "model_params = {\"input_dim\": input_dim, \"hidden_dim\": 512, \"output_dim\": output_dim}\n",
    "params_path = model_path + \".params.json\"\n",
    "with open(params_path, \"w\") as f:\n",
    "    json.dump(model_params, f)\n",
    "print(f\"Model parameters saved to {params_path}\")\n",
    "\n",
    "# Optionally, evaluate the model on the test set\n",
    "test_loss, per_target_metrics = evaluate_model(model, test_dataset, batch_size=64)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "for metric in per_target_metrics:\n",
    "    print(metric)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
